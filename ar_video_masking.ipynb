{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "systematic-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "olive-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0) #camera feed\n",
    "target=cv2.imread('21.jpeg') #image target\n",
    "target=cv2.resize(target,(726,512)) #reshaping\n",
    "vid=cv2.VideoCapture('2.mp4') # video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('target',target)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elect-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht,wt,ct=target.shape #getting target dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "outside-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "success,frame=vid.read() #getting frame of video\n",
    "imgvid=cv2.resize(frame,(ht,wt)) #resizing frame to image dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "victorian-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image video',imgvid)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-labor",
   "metadata": {},
   "source": [
    "**ORB Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "corporate-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb=cv2.ORB_create(nfeatures=1000) #feature detector to detect atmost 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greek-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key points and the Descriptors for the Target Image.\n",
    "key,des=orb.detectAndCompute(target,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "miniature-toddler",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv2.imshow('detected features',cv2.drawKeypoints(target,kps,None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-russian",
   "metadata": {},
   "source": [
    "**SURF Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "higher-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf=cv2.xfeatures2d.SURF_create()\n",
    "key,des=surf.detectAndCompute(target,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "northern-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('surf keypoints',cv2.drawKeypoints(target,key,None))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-lafayette",
   "metadata": {},
   "source": [
    "**SIFT Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "determined-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift=cv2.xfeatures2d.SIFT_create()\n",
    "key,des=sift.detectAndCompute(target,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lyric-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('sift keypoints',cv2.drawKeypoints(target,key,None))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-leader",
   "metadata": {},
   "source": [
    "### Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aboriginal-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo=\"sift\"\n",
    "method={\"orb\":orb,\"surf\":surf,\"sift\":sift}\n",
    "kp1,des=method[algo].detectAndCompute(target,None)\n",
    "while True:\n",
    "#     matrix=[]\n",
    "    success,frame=cap.read()\n",
    "    imgaug=frame.copy()\n",
    "    r,f=vid.read()\n",
    "    if not r:\n",
    "        vid=cv2.VideoCapture('2.mp4')\n",
    "        r,f=vid.read()\n",
    "    kp2,des2=method[algo].detectAndCompute(frame,None)\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des, des2, k=2)\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.80 * n.distance:\n",
    "            good.append(m)\n",
    "#     print(len(good))\n",
    "    thresholds={\"orb\":12,\"surf\":200,\"sift\":140}\n",
    "    #homography : to find relevant relations btw src and target points\n",
    "    if len(good)>=thresholds[algo]:\n",
    "        srcPts=np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n",
    "        desPts=np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n",
    "        matrix,mask=cv2.findHomography(srcPts,desPts,cv2.RANSAC,5.0)\n",
    "#     print(matrix)\n",
    "        pts=np.float32([[0,0],[0,ht],[wt,ht],[wt,0]]).reshape(-1,1,2)\n",
    "        dst=cv2.perspectiveTransform(pts,matrix) #perspective transform to get the bounding box\n",
    "        bbox=cv2.polylines(frame,[np.int32(dst)],True,(0,255,0),3)\n",
    "        f=cv2.resize(f,(wt,ht))\n",
    "        vid_warp=cv2.warpPerspective(f,matrix,(bbox.shape[1],bbox.shape[0]))\n",
    "        mask_new=np.zeros((bbox.shape[0],bbox.shape[1]),np.uint8)\n",
    "        cv2.fillPoly(mask_new,[np.int32(dst)],(255,255,255))\n",
    "        \n",
    "    else:\n",
    "        bbox=frame\n",
    "        vid_warp=frame\n",
    "        mask_new=np.zeros((bbox.shape[0],bbox.shape[1]),np.uint8)\n",
    "        \n",
    "    features=cv2.drawMatches(target,kp1,frame,kp2,good,None,flags=2)\n",
    "\n",
    "    maskInv=cv2.bitwise_not(mask_new)\n",
    "    imgaug=cv2.bitwise_and(imgaug,imgaug,mask=maskInv)\n",
    "    imgaug=cv2.bitwise_or(imgaug,vid_warp)\n",
    "#     cv2.imshow('feature match',features)\n",
    "    cv2.imshow('vision ar',imgaug)\n",
    "#     cv2.imshow('mask',maskInv)\n",
    "#     cv2.imshow('bounding box',bbox)\n",
    "#     cv2.imshow('warp',vid_warp)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-toner",
   "metadata": {},
   "source": [
    "### Descriptor matching (multiple images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "connected-contribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12529229199935799\n",
      "0.12963616299748537\n",
      "0.14443002500047442\n",
      "0.13430013300239807\n",
      "0.13514467799905105\n",
      "0.13989165300154127\n",
      "0.13741683800253668\n",
      "0.14482785200016224\n",
      "0.14502820300185704\n",
      "0.13879069500035257\n",
      "0.14066317600008915\n",
      "0.14135330999852158\n",
      "0.13494770000033895\n",
      "0.1410260209995613\n",
      "0.1391724040004192\n",
      "0.13585393099856446\n",
      "0.13857981800174457\n",
      "0.13047427399942535\n",
      "0.13568982200013124\n",
      "0.1373684210011561\n",
      "0.1392536100029247\n",
      "0.14167888100200798\n",
      "0.13821302699943772\n",
      "0.13984913600143045\n",
      "0.1237938039994333\n",
      "0.12121020400081761\n"
     ]
    }
   ],
   "source": [
    "#Descriptor matching\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import perf_counter\n",
    "\n",
    "sift=cv2.xfeatures2d.SIFT_create()    #creating sift feature matcher\n",
    "kp,desc=[],[]                         #empty list to contain all the key points and descriptor\n",
    "for i in range(9):                    #looping through range of images\n",
    "    img=cv2.imread(f'{i+1}.jpeg')     #reading image\n",
    "    img=cv2.resize(img,(726,512))     #resizing image\n",
    "    key,des=sift.detectAndCompute(img,None) #getting kp's and des\n",
    "    kp.append(key)                    #appending keys and descriptors to the lists\n",
    "    desc.append(des)  \n",
    "ht,wt,ct=img.shape                    #getting image shape \n",
    "cap=cv2.VideoCapture(0)               #create camera feed object\n",
    "thresh=145                            #setting a threshold for matches\n",
    "i=0                                   #setting initial index to zero\n",
    "match=False                           #feed loop yet to start so match = false\n",
    "\n",
    "while True:                           #camera frame feed loop\n",
    "#     matrix=[]\n",
    "    if match:                         #if match is already true then continue reading the target video frames\n",
    "        r,f=vid.read()\n",
    "    success,frame=cap.read()          #getting camera frame\n",
    "    t1_start = perf_counter()         #time counter start\n",
    "    imgaug=frame.copy()               #copy of the frame\n",
    "    kp2,des2=sift.detectAndCompute(frame,None) #getting kp and des for the frame\n",
    "    bf = cv2.BFMatcher()              #create brute force matcher object\n",
    "    if i>=9:                          #if index exceeds 9 then switch back to 0\n",
    "        i=0\n",
    "    matches = bf.knnMatch(desc[i], des2, k=2) #getting matches by comparing descriptors with knn \n",
    "    good = []                         #container list to store matches\n",
    "    for m, n in matches:              #for match from img if the distance is less than 80% of distance from feed then append that match\n",
    "        if m.distance < 0.80 * n.distance:\n",
    "            good.append(m)\n",
    "    if len(good)>=thresh:             #if good matches are greater than threshold\n",
    "        t2_end = perf_counter()       #its a match check point the timer again\n",
    "        print(t2_end-t1_start)        \n",
    "#         print(len(good))\n",
    "#         cap.release()\n",
    "#         break\n",
    "        if not match:                 #if match was false \n",
    "            vid=cv2.VideoCapture(f'{i+1}.mp4') #read from video \n",
    "            img=cv2.imread(f'{i+1}.jpeg')\n",
    "            r,f=vid.read()\n",
    "        match=True                    #set match to true\n",
    "        srcPts=np.float32([kp[i][m.queryIdx].pt for m in good]).reshape(-1,1,2)  #get the source points i.e image points\n",
    "        desPts=np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1,1,2)    #get the destination points i.e points from video\n",
    "        matrix,mask=cv2.findHomography(srcPts,desPts,cv2.RANSAC,5.0)             #find homography matrix\n",
    "#     print(matrix)\n",
    "        pts=np.float32([[0,0],[0,ht],[wt,ht],[wt,0]]).reshape(-1,1,2)            #create points for  perspective transform\n",
    "        dst=cv2.perspectiveTransform(pts,matrix) #perspective transform to get the bounding box\n",
    "        bbox=cv2.polylines(frame,[np.int32(dst)],True,(0,255,0),3)               #creating a bounding box with poly lines inside frame\n",
    "        f=cv2.resize(f,(wt,ht))       #resize the video frame to the size of image\n",
    "        vid_warp=cv2.warpPerspective(f,matrix,(bbox.shape[1],bbox.shape[0]))     #perspective warp the video frame for localization\n",
    "        mask_new=np.zeros((bbox.shape[0],bbox.shape[1]),np.uint8)                #create a mask of shape of bounding box\n",
    "        cv2.fillPoly(mask_new,[np.int32(dst)],(255,255,255))                     #fill the remaining mask with white\n",
    "    else:\n",
    "        match=False                                                              #if matches are less than thresh value\n",
    "        bbox=frame                                                               #set match to False\n",
    "        vid_warp=frame\n",
    "        mask_new=np.zeros((bbox.shape[0],bbox.shape[1]),np.uint8)               \n",
    "#     features=cv2.drawMatches(img,kp[i],frame,kp2,good,None,flags=2)              #optional to drow matches\n",
    "    maskInv=cv2.bitwise_not(mask_new)                                            #inverse the color of created mask by bitwise not\n",
    "    imgaug=cv2.bitwise_and(imgaug,imgaug,mask=maskInv)                           #bitwise &, the frame and the masked box\n",
    "    imgaug=cv2.bitwise_or(imgaug,vid_warp)                                       #bitwise or ,the masked video and the frame \n",
    "    cv2.imshow('vision ar',imgaug)                                               #  show frame\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if not match:                                                                #if not a match the increment the index\n",
    "        i+=1\n",
    "# img=cv2.imread(f'{i+1}.jpeg')\n",
    "# print(\"Avg. time\", t2_end - t1_start)\n",
    "# cv2.imshow('matched',cv2.resize(img,(726,512)))\n",
    "# cv2.waitKey()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "boring-concentration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2277, 128)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "muslim-ceramic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "perceived-illinois",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-egypt",
   "metadata": {},
   "source": [
    "### Barcode/QRcode generation and detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jewish-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "import barcode \n",
    "from barcode.writer import ImageWriter\n",
    "from pyzbar import pyzbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar=barcode.get('code128','vaibhav haswani123',writer=ImageWriter()) #generating custom barcode \n",
    "bar.get_fullcode()\n",
    "bar.save('bar1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "retired-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyqrcode\n",
    "from PIL import Image\n",
    "url = pyqrcode.QRCode('http://www.eqxiu.com',error = 'H')\n",
    "url.png('test.png',scale=10)\n",
    "im = Image.open('test.png')\n",
    "im = im.convert(\"RGBA\")\n",
    "logo = Image.open('1.jpeg')\n",
    "box = (135,135,235,235)\n",
    "im.crop(box)\n",
    "region = logo\n",
    "region = region.resize((box[2] - box[0], box[3] - box[1]))\n",
    "im.paste(region,box)\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "grave-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyqrcode\n",
    "from PIL import Image\n",
    "\n",
    "# Generate the qr code and save as png\n",
    "qrobj = pyqrcode.create('https://stackoverflow.com')\n",
    "with open('test.png', 'wb') as f:\n",
    "    qrobj.png(f, scale=10)\n",
    "\n",
    "# Now open that png image to put the logo\n",
    "img = Image.open('test.png')\n",
    "width, height = img.size\n",
    "\n",
    "# How big the logo we want to put in the qr code png\n",
    "logo_size = 2000\n",
    "\n",
    "# Open the logo image\n",
    "logo = Image.open('logo.jpeg')\n",
    "\n",
    "# Calculate xmin, ymin, xmax, ymax to put the logo\n",
    "xmin = ymin = int((width / 2) - (logo_size / 2))\n",
    "xmax = ymax = int((width / 2) + (logo_size / 2))\n",
    "\n",
    "# resize the logo as calculated\n",
    "logo = logo.resize((xmax - xmin, ymax - ymin))\n",
    "\n",
    "# put the logo in the qr code\n",
    "img.paste(logo, (xmin, ymin, xmax, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "attended-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import qrcode\n",
    "from PIL import Image\n",
    "\n",
    "Logo_link = '1.jpeg'#input('Please enter the path for your logo: ')\n",
    "\n",
    "logo = Image.open(Logo_link)\n",
    "basewidth = 250 #int(input('Please Enter the Base Width [Default=75]: ') or '75')\n",
    "wpercent = (basewidth/float(logo.size[0]))\n",
    "hsize = int((float(logo.size[1])*float(wpercent)))\n",
    "logo = logo.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "qr_big = qrcode.QRCode(\n",
    "    error_correction=qrcode.constants.ERROR_CORRECT_H,\n",
    "    box_size=20,\n",
    "    border=1\n",
    ")\n",
    "data='hello world' #data for qr#nput('Please enter the URL after clicking: ')\n",
    "qr_big.add_data(data)\n",
    "qr_big.make()\n",
    "qr_color = 'blue' #input('What Color Would You like Your QR Code to be? [Default=Black]: ' or 'Black')\n",
    "img_qr_big = qr_big.make_image(fill_color=qr_color, back_color=\"white\").convert('RGB')\n",
    "pos = ((img_qr_big.size[0] - logo.size[0]) // 2, (img_qr_big.size[1] - logo.size[1]) // 2)\n",
    "img_qr_big.paste(logo, pos)\n",
    "save_path = 'logo.png' #input('Please enter the filename you want for your branded qr code: ')\n",
    "img_qr_big.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "internal-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('logo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "annual-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=cv2.resize(img,(512,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('reshaped',i)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-focus",
   "metadata": {},
   "source": [
    "### Aruco Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broadband-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.aruco as aruco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-drilling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
